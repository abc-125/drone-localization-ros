#!/usr/bin/env python

# based on https://github.com/DavidFernandezChaves/Detectron2_ros

import sys
import threading
import time

import cv2 as cv
import numpy as np
import rospy
from cv_bridge import CvBridge
from image_geometry import PinholeCameraModel

from detectron2.config import get_cfg
from detectron2.data import MetadataCatalog
from detectron2.utils.logger import setup_logger
from detectron2.utils.visualizer import Visualizer

from drone_localization_ros.msg import Detection, Detections, PosesWithCovariance
from sensor_msgs.msg import Image, CameraInfo
import message_filters

from predictorNoResize import PredictorNoResize
from localization import get_poses_msg



class DroneLocalizationNode(object):
    def __init__(self):
        rospy.logwarn("Initializing")
        setup_logger()

        self.mode = self.load_param('~network_mode')  # small / large / dual
        self.is_fusion = self.load_param('~is_fusion')  # use halfway fusion or not

        if self.is_fusion:
            from halfway_fusion.predictor import HalfwayFusionPredictor

        self._bridge = CvBridge()
        self._last_msg = None
        self._msg_lock = threading.Lock()
        self._image_counter = 0

        self.camera = PinholeCameraModel()
        self._camera_info = None
        self._drone_width = self.load_param('~drone_width')
        self.covariance_xy = 0.05
        self.covariance_z = 0.5

        self.original_input_size = None
        self.input_size = (640, 512)

        # either small or large neural network
        if self.mode != "dual":
            self.cfg1 = get_cfg()

            if self.mode == "small":
                self.cfg1.merge_from_file(self.load_param('~config_small'))
                self.cfg1.MODEL.WEIGHTS = self.load_param('~model_small')

            if self.mode == "large":
                self.cfg1.merge_from_file(self.load_param('~config_large'))
                self.cfg1.MODEL.WEIGHTS = self.load_param('~model_large')

            self.cfg1.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 32, 64, 128, 256]]
            self.cfg1.MODEL.ROI_HEADS.SCORE_THRESH_TEST = self.load_param('~detection_threshold')
            self.cfg1.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.5, 1.0]]
            self.cfg1.MODEL.ROI_HEADS.NUM_CLASSES = 1 
            self.cfg1.MODEL.DEVICE='cpu'  # for test and compatibility

            if self.is_fusion:
                self.cfg1.MODEL.META_ARCHITECTURE = "HalfwayFusionRCNN"
                self.cfg1.MODEL.BACKBONE.NAME = "build_hw_fusion_resnet_fpn_backbone"
                self.predictor = HalfwayFusionPredictor(self.cfg1)
            else:
                self.predictor = PredictorNoResize(self.cfg1)
    
        # both neural networks
        if self.mode == "dual":
            self.no_detections_treshold = self.load_param('~no_detections_treshold')

            self.cfg1 = get_cfg()
            self.cfg1.merge_from_file(self.load_param('~config_small'))
            self.cfg1.MODEL.WEIGHTS = self.load_param('~model_small')

            self.cfg2 = get_cfg()
            self.cfg2.merge_from_file(self.load_param('~config_large'))
            self.cfg2.MODEL.WEIGHTS = self.load_param('~model_large')

            self.cfg1.MODEL.ANCHOR_GENERATOR.SIZES = self.cfg2.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 32, 64, 128, 256]]            
            self.cfg1.MODEL.ROI_HEADS.SCORE_THRESH_TEST = self.cfg2.MODEL.ROI_HEADS.SCORE_THRESH_TEST = self.load_param('~detection_threshold')
            self.cfg1.MODEL.ROI_HEADS.NUM_CLASSES = self.cfg2.MODEL.ROI_HEADS.NUM_CLASSES = 1 
            self.cfg1.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = self.cfg2.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.5, 1.0]]
            self.cfg1.MODEL.DEVICE = self.cfg2.MODEL.DEVICE = 'cpu'  # for test and compatibility

            if self.is_fusion:
                self.cfg1.MODEL.META_ARCHITECTURE = self.cfg2.MODEL.META_ARCHITECTURE = "HalfwayFusionRCNN"
                self.cfg1.MODEL.BACKBONE.NAME = self.cfg2.MODEL.META_ARCHITECTURE = "build_hw_fusion_resnet_fpn_backbone"
                self.predictor1 = HalfwayFusionPredictor(self.cfg1)
                self.predictor2 = HalfwayFusionPredictor(self.cfg2)
            else:
                self.predictor1 = PredictorNoResize(self.cfg1)
                self.predictor2 = PredictorNoResize(self.cfg2)

        MetadataCatalog.get(self.cfg1.DATASETS.TRAIN[0]).set(thing_classes=["drone"])  # set class name
        self._class_names = MetadataCatalog.get(self.cfg1.DATASETS.TRAIN[0]).get("thing_classes", None)

        self._visualization = self.load_param('~visualization', True)

        self._detections_pub = rospy.Publisher('~detections', Detections, queue_size=1)
        self._poses_pub = rospy.Publisher('~poses', PosesWithCovariance, queue_size=1)
        self._vis_pub = rospy.Publisher('~visualization', Image, queue_size=1)

        if self.is_fusion:
            sub_rgb = message_filters.Subscriber(self.load_param('~input_images_rgb'), Image, queue_size=1)
            self._sub_cam_info_rgb = rospy.Subscriber(self.load_param('~camera_info_rgb'), CameraInfo, self.callback_cam_info, queue_size=1)
            sub_t = message_filters.Subscriber(self.load_param('~input_images_t'), Image, queue_size=1)
            self._sync_images = message_filters.ApproximateTimeSynchronizer([sub_rgb, sub_t], queue_size=5, slop=0.1)
            self._sync_images.registerCallback(self.callback_sync_images)
        else:
            self._sub = rospy.Subscriber(self.load_param('~input_images'), Image, self.callback_image, queue_size=1)
            self._sub_cam_info = rospy.Subscriber(self.load_param('~camera_info'), CameraInfo, self.callback_cam_info, queue_size=1)

        self.start_time = time.time()
        rospy.logwarn("Initialized")


    def run(self):
        rate = rospy.Rate(100)
        detections_counter = 0

        while not rospy.is_shutdown():
            if self._msg_lock.acquire(False):
                img_msg = self._last_msg
                self._last_msg = None
                self._msg_lock.release()
            else:
                rate.sleep()
                continue

            if img_msg and self._camera_info:
                # convert and resize one input image or both
                if not self.is_fusion:
                    np_image = self.convert_to_cv_image(img_msg)
                    np_image = cv.resize(np_image, self.input_size)
                else:
                    np_image_rgb, np_image_t = self.convert_to_cv_image(img_msg[0]), self.convert_to_cv_image(img_msg[1])
                    crop_w = int(img_msg[1].height / img_msg[1].width * img_msg[0].width)
                    diff = int((img_msg[0].width - crop_w) / 2)
                    np_image_rgb = np_image_rgb[0:img_msg[0].height, diff:crop_w + diff] # crop rgb image
                    np_image_rgb, np_image_t = cv.resize(np_image_rgb, self.input_size), cv.resize(np_image_t, self.input_size)
                    np_image = np_image_rgb, np_image_t
                
                # small or large mode (one neural network)
                if self.mode != "dual":
                    outputs = self.predictor(np_image)

                # dual mode (two neural networks)
                else:
                    if detections_counter < self.no_detections_treshold:
                        outputs = self.predictor1(np_image)  # use faster network
                    else:
                        rospy.loginfo("[DroneLocalization]: Cannot detect target, using larger neural network for detection...")
                        outputs = self.predictor2(np_image)  # use slower network if no detections for some number of images                      

                    if not detections:
                        detections_counter += 1
                    else:
                        detections_counter = 0

                detections = outputs["instances"].to("cpu") 

                # publish detections
                dets_msg = self.get_detections_msg(detections)
                self._detections_pub.publish(dets_msg)
                #rospy.loginfo(dets_msg)

                # calculate relative localizations
                poses_msg = get_poses_msg(self, dets_msg)
                self._poses_pub.publish(poses_msg)
                   
                # visualize results
                if self._visualization:
                    if not self.is_fusion:
                        v = Visualizer(np_image[:, :, ::-1], MetadataCatalog.get(self.cfg1.DATASETS.TRAIN[0]), scale=1.0)
                    else:
                        v = Visualizer(np_image[0][:, :, ::-1], MetadataCatalog.get(self.cfg1.DATASETS.TRAIN[0]), scale=1.0)
                    v = v.draw_instance_predictions(detections)
                    img = v.get_image()[:, :, ::-1]

                    image_msg = self._bridge.cv2_to_imgmsg(img, 'bgr8')
                    self._vis_pub.publish(image_msg)

                # count processing time
                self._image_counter = self._image_counter + 1
                if (self._image_counter % 11) == 10:
                    rospy.loginfo("Images detected per second=%.2f",
                                  float(self._image_counter) / (time.time() - self.start_time))

            rate.sleep()


    def get_detections_msg(self, detections):
        boxes = detections.pred_boxes if detections.has("pred_boxes") else None

        dets_msg = Detections()
        dets_msg.header = self._header

        for i, (x1, y1, x2, y2) in enumerate(boxes):
            det_msg = Detection()

            det_msg.class_id = detections.pred_classes[i].numpy()
            det_msg.label = self._class_names[det_msg.class_id]
            det_msg.confidence = detections.scores[i].numpy()

            det_msg.xmin = np.uint32(x1)
            det_msg.ymin = np.uint32(y1)
            det_msg.xmax = np.uint32(x2)
            det_msg.ymax = np.uint32(y2)

            dets_msg.detections.append(det_msg)

        return dets_msg


    def convert_to_cv_image(self, image_msg):
        if image_msg is None:
            return None

        cv_img = self._bridge.imgmsg_to_cv2(image_msg)

        if image_msg.encoding.lower() == 'mono8':
            #cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2GRAY)
            cv_img = cv.cvtColor(cv_img, cv.COLOR_GRAY2BGR)  # TODO - quick fix for now
            cv_img = cv.normalize(cv_img, None, 0, 255, cv.NORM_MINMAX, cv.CV_8U)  # normalizing for thermal images

        return cv_img


    def callback_sync_images(self, image_rgb, image_t):     
        rospy.logdebug("Got both images")
        crop_w = int(image_t.height / image_t.width * image_rgb.width)
        if not self.original_input_size:
            self.original_input_size = (crop_w, image_rgb.height)

        if self._msg_lock.acquire(False):
            self._last_msg = (image_rgb, image_t)
            self._header = image_rgb.header
            self._msg_lock.release()


    def callback_image(self, msg):
        rospy.logdebug("Got an image")
        if not self.original_input_size:
            self.original_input_size = (msg.width, msg.height)
        if self._msg_lock.acquire(False):
            self._last_msg = msg
            self._header = msg.header
            self._msg_lock.release()


    def callback_cam_info(self, msg):
        #     [fx'  0  cx' Tx]
        # P = [ 0  fy' cy' Ty]
        #     [ 0   0   1   0]
        rospy.logdebug("Got camera info")
        if not self._camera_info and self.original_input_size:
            self._camera_info = msg

            fx = self._camera_info.P[0] / self.original_input_size[0] * self.input_size[0]
            fy = self._camera_info.P[5] / self.original_input_size[1] * self.input_size[1]
            cx = self.input_size[0] / 2
            cy = self.input_size[1] / 2
            self._camera_info.P = list(self._camera_info.P)
            self._camera_info.P[0] = fx
            self._camera_info.P[5] = fy
            self._camera_info.P[2] = cx
            self._camera_info.P[6] = cy
            self._camera_info.P = tuple(self._camera_info.P)

            self.camera.fromCameraInfo(self._camera_info)


    @staticmethod
    def load_param(param, default=None):
        new_param = rospy.get_param(param, default)
        rospy.loginfo("[DroneLocalization] %s: %s", param, new_param)
        return new_param


def main(argv):
    rospy.init_node('drone_localization_ros')
    node = DroneLocalizationNode()
    node.run()


if __name__ == '__main__':
    main(sys.argv)
